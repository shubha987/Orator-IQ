{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def extract_audio(video_file, output_audio_file):\n",
        "    command = f\"ffmpeg -i {video_file} -q:a 0 -map a {output_audio_file} -y\"\n",
        "    subprocess.run(command, shell=True, check=True)\n",
        "\n",
        "# Example usage\n",
        "video_file = \"HR.mp4\"\n",
        "audio_file = \"response_audio.wav\"\n",
        "extract_audio(video_file, audio_file)\n"
      ],
      "metadata": {
        "id": "ae-TdGSdj50e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import noisereduce as nr\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Load audio\n",
        "audio, sr = librosa.load(\"response_audio.wav\", sr=16000)\n",
        "\n",
        "# Apply noise reduction\n",
        "reduced_noise = nr.reduce_noise(y=audio, sr=sr)\n",
        "\n",
        "# Save processed audio\n",
        "sf.write(\"processed_audio.wav\", reduced_noise, sr)\n"
      ],
      "metadata": {
        "id": "1AFKuPcWj8Zn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import wave\n",
        "\n",
        "def real_time_transcription(audio_file):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    audio = whisper.load_audio(audio_file)\n",
        "    transcription = model.transcribe(audio)\n",
        "    print(\"Transcription:\", transcription[\"text\"])\n",
        "    return transcription[\"text\"]\n",
        "\n",
        "# Usage\n",
        "# Save live audio to 'audio.wav' in real time\n",
        "transcription = real_time_transcription(\"processed_audio.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpMHjpxiie0X",
        "outputId": "f8f94d82-a007-419b-cf72-beaee8d11754"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 61.2MiB/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:  Have you received? Yes, my name is Rizim. What you could make? My name is Rizim Rekres from it. So, Rizim, today you are going to come take a walk into the hall or an extra right desk. So, 10 month ago, yes, firstly, and then to give you a 30-minute service, to introduce this writer, my name is Rizim Rekres from it. I am from the work of studies in Gaita, Sanctuary. I completed my PhD in the Seabop, Computer Science and Engineering, in Gaita, Sanctuary, and in the college, I have a good hall of the village. I set up my PhD with sound coin, 960, CTA. Coming to my family, there are former Muslim family, Ebrood Budi, and my technical skills are, and Budi, C. E. Paita, data switches, and basics of the school. And my interpersonal skills are, I am able to communicate with them in people's and good listener. And my hobby is spending time with family and friends, cooking, listening music, and crafting at three times. My stents are, I am a Holger, and B. Budi, and I am a self-motivator. And coming to my good, my short term good is to be in a position where I place my hot and my optimal is to become a successful person, and helps to a risk. But should I hire you? I hope I should work, and I am to plan the good part of it, and I am always ready to do Holger to complete it fast on time, and I think this pattern and this position will help me to gain these skills and knowledge, and achieve my goals. So, Xiaomi, I am here for this difference between smarter and harder, it's not a difference between Holger and smarter. Hard work involves putting a significant amount of efforts and time to accomplish it fast. Smart work involves trying to make a more efficient and effective way to finally solution for the same task with the less efforts, and I am going to do it with less efforts, but with the both combination, we will get the success. Are you ready to relocate? Yes, I would like to relocate, and I am always ready to move to other places, and explore the places, and I am always happy to work with the new people with different culture, it used to explain to me. Then you want to see yourself in next two or five years, in next two or five years, I want to be good position in the competition. That means, technically, we need the team in company, we will have a place, and we will plan my career accordingly. So, what is important for you in your life, for Alkal Mali? Yes, ma'am. Mostly, I think it worked more than we were money, because if you work perfectly, you will gain the knowledge and skills and experiences. It does not mean my money is not important, it means money is also important to me, but not more than we were money gives financial support and security, but we are used to work satisfaction and knowledge, if you have work knowledge, you automatically will get the money. For that is salary expectation. As a pressure, my first priority is to enhance my skills, knowledge and experience. Coming to the service, I will go according to the company norms, and I will expect the considerable salary for this position, it will help you carry economic needs. What are your weakness, Shavi? I will be able to witness sometimes, I get to details of the work. And spending more time in me is not a result, but now I have been working on it, and taking myself and working on the features, potential my skills, and you work satisfaction. How would you rate yourself on a scale of 1 to 10? I would like to rate myself as 1.1. I know that I am not perfect, I think I always keep that. There is always a scope for lending and improvement. My thinking is that the continuous lending is a fundamental right to personal and fundamental part to personal and professional growth. When you like for the company, I try to find solution for the problem. If I write down later the company will face the problem because of me. It is not a good firm company, and not firm. For every problem, there is a solution. I try to resolve this problem. If I have a home address, it is situation demands, it is a property growth of company. I will play it. Okay, so we have done this already. Thank you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import language_tool_python\n",
        "\n",
        "def grammar_analysis(text):\n",
        "    tool = language_tool_python.LanguageTool('en-IN')\n",
        "    matches = tool.check(text)\n",
        "    errors = [match.ruleId for match in matches]\n",
        "    suggestions = [match.message for match in matches]\n",
        "    return errors, suggestions\n",
        "\n",
        "# Example Usage\n",
        "text = \"This is an test sentence with error.\"\n",
        "errors, suggestions = grammar_analysis(text)\n",
        "print(\"Errors:\", errors)\n",
        "print(\"Suggestions:\", suggestions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwCUNeXDkvXl",
        "outputId": "ec59d5c5-1c6a-4709-83c9-38b897b0676c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [00:12<00:00, 20.2MB/s]\n",
            "INFO:language_tool_python.download_lt:Unzipping /tmp/tmpdcu3942e.zip to /root/.cache/language_tool_python.\n",
            "INFO:language_tool_python.download_lt:Downloaded https://www.languagetool.org/download/LanguageTool-6.4.zip to /root/.cache/language_tool_python.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errors: ['EN_A_VS_AN']\n",
            "Suggestions: ['Use “a” instead of ‘an’ if the following word doesn’t start with a vowel sound, e.g. ‘a sentence’, ‘a university’.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import cmudict\n",
        "\n",
        "def check_pronunciation(word):\n",
        "    pronunciation = cmudict.dict()\n",
        "    return pronunciation.get(word.lower(), \"Word not found in dictionary\")\n",
        "\n",
        "# Example Usage\n",
        "word = \"hello\"\n",
        "result = check_pronunciation(word)\n",
        "print(f\"Pronunciation for '{word}': {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8pl4-B_kyj8",
        "outputId": "388e1c5c-afd1-4c9a-9d69-74092d0d7adb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pronunciation for 'hello': [['HH', 'AH0', 'L', 'OW1'], ['HH', 'EH0', 'L', 'OW1']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def speaking_rate(transcribed_text, duration_seconds):\n",
        "    words = len(transcribed_text.split())\n",
        "    rate = words / (duration_seconds / 60)  # Words per minute\n",
        "    return rate\n",
        "\n",
        "# Example Usage\n",
        "transcription = \"This is a sample sentence for evaluation.\"\n",
        "rate = speaking_rate(transcription, 45)\n",
        "print(f\"Speaking Rate: {rate} WPM\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUAw8rqLk8Fn",
        "outputId": "15555c69-0438-47e4-948c-a615a1b413ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaking Rate: 9.333333333333334 WPM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment, silence\n",
        "\n",
        "def pause_analysis(audio_file):\n",
        "    audio = AudioSegment.from_wav(audio_file)\n",
        "    pauses = silence.detect_silence(audio, min_silence_len=500, silence_thresh=-40)\n",
        "    return len(pauses), pauses\n",
        "\n",
        "# Example Usage\n",
        "num_pauses, pause_details = pause_analysis(\"processed_audio.wav\")\n",
        "print(f\"Number of Pauses: {num_pauses}\")\n",
        "print(\"Pause Durations:\", pause_details)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGuHvZDlk-N3",
        "outputId": "f9b61a41-54f4-4c53-a6dc-cb6341f6bb64"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Pauses: 3\n",
            "Pause Durations: [[0, 172230], [172581, 195434], [195446, 278036]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filler_word_usage(text):\n",
        "    fillers = [\"um\", \"uh\", \"like\", \"you know\", \"sort of\"]\n",
        "    filler_count = {filler: text.lower().count(filler) for filler in fillers}\n",
        "    return filler_count\n",
        "\n",
        "# Example Usage\n",
        "text = \"Um, I think this is, like, a sort of test.\"\n",
        "fillers = filler_word_usage(text)\n",
        "print(\"Filler Word Usage:\", fillers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHqqPLSqlBJG",
        "outputId": "f6fa4bb3-3ff7-47ac-9652-d20519b20a62"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filler Word Usage: {'um': 1, 'uh': 0, 'like': 1, 'you know': 0, 'sort of': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "\n",
        "def calculate_snr(audio_file):\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "    samples = np.array(audio.get_array_of_samples())\n",
        "    signal = np.mean(samples**2)\n",
        "    noise = np.var(samples)\n",
        "    snr = 10 * np.log10(signal / noise)\n",
        "    return snr\n",
        "\n",
        "# Example Usage\n",
        "snr = calculate_snr(\"processed_audio.wav\")\n",
        "print(f\"Signal-to-Noise Ratio: {snr} dB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5izPD_EJlEMb",
        "outputId": "3ba74b83-8ce0-4c18-f177-66efbd27b31c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Signal-to-Noise Ratio: -9.984965081863532 dB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feedback(transcription, audio_file, duration):\n",
        "    # Grammar\n",
        "    errors, suggestions = grammar_analysis(transcription)\n",
        "\n",
        "    # Speaking Rate\n",
        "    rate = speaking_rate(transcription, duration)\n",
        "\n",
        "    # Pause Patterns\n",
        "    num_pauses, pauses = pause_analysis(audio_file)\n",
        "\n",
        "    # Filler Word Usage\n",
        "    fillers = filler_word_usage(transcription)\n",
        "\n",
        "    # Voice Clarity\n",
        "    snr = calculate_snr(audio_file)\n",
        "\n",
        "    feedback = {\n",
        "        \"Grammar Errors\": errors,\n",
        "        \"Grammar Suggestions\": suggestions,\n",
        "        \"Speaking Rate (WPM)\": rate,\n",
        "        \"Number of Pauses\": num_pauses,\n",
        "        \"Pause Details (ms)\": pauses,\n",
        "        \"Filler Word Usage\": fillers,\n",
        "        \"Voice Clarity (SNR in dB)\": snr,\n",
        "    }\n",
        "    return feedback\n",
        "\n",
        "# Example Usage\n",
        "transcription = \"This is um a sample uh response with errors.\"\n",
        "feedback = generate_feedback(transcription, \"processed_audio.wav\", 45)\n",
        "for key, value in feedback.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFjvKnJrlHkf",
        "outputId": "1e4625e2-181b-46b4-bae8-1363ddd538f1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar Errors: []\n",
            "Grammar Suggestions: []\n",
            "Speaking Rate (WPM): 12.0\n",
            "Number of Pauses: 3\n",
            "Pause Details (ms): [[0, 172230], [172581, 195434], [195446, 278036]]\n",
            "Filler Word Usage: {'um': 1, 'uh': 1, 'like': 0, 'you know': 0, 'sort of': 0}\n",
            "Voice Clarity (SNR in dB): -9.984965081863532\n"
          ]
        }
      ]
    }
  ]
}